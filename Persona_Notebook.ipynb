{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocessing PDFS to Extract Text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import os\n",
    "import re\n",
    "from itertools import zip_longest\n",
    "from PIL import Image\n",
    "Image.MAX_IMAGE_PIXELS = None\n",
    "from pdf2image import convert_from_path\n",
    "import pytesseract\n",
    "import math\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Input Needed:\n",
    "pdf_path = 'FriendMessage.pdf'\n",
    "output_path = 'FriendMessage.csv'\n",
    "total_pages = 29\n",
    "pages_per_chunk = 5\n",
    "\n",
    "#scan pdf images, and separate Left side for prompts, and right side for completions\n",
    "def convert_pdf_to_images(pdf_path, start_page, end_page):\n",
    "    return convert_from_path(pdf_path, dpi=200, first_page=start_page, last_page=end_page)\n",
    "\n",
    "def ocr_core(image):\n",
    "    text = pytesseract.image_to_string(image)\n",
    "    return text\n",
    "\n",
    "def split_into_blocks(text):\n",
    "    blocks = re.split('\\n\\s*\\n', text)\n",
    "    blocks = [block.strip() for block in blocks]\n",
    "    blocks = [block for block in blocks if block]\n",
    "\n",
    "    merged_blocks = []\n",
    "    current_block = []\n",
    "    for block in blocks:\n",
    "        if block.endswith('\\n'):\n",
    "            current_block.append(block)\n",
    "        else:\n",
    "            current_block.append(block)\n",
    "            merged_blocks.append(' '.join(current_block))\n",
    "            current_block = []\n",
    "    if current_block:\n",
    "        merged_blocks.append(' '.join(current_block))\n",
    "\n",
    "    return merged_blocks\n",
    "\n",
    "def filter_text_blocks(left_blocks, right_blocks, patterns):\n",
    "    new_left_blocks = []\n",
    "    new_right_blocks = []\n",
    "    seen_left_blocks = set()  # a set to keep track of the seen left blocks\n",
    "    for i, right_block in enumerate(right_blocks):\n",
    "        if right_block and not any(re.search(pattern, right_block) for pattern in patterns):\n",
    "            if i < len(left_blocks):  # to ensure we don't go out of index\n",
    "                left_block = left_blocks[i]\n",
    "                if left_block and not any(re.search(pattern, left_block) for pattern in patterns):  # only if there's text on the left\n",
    "                    if left_block not in seen_left_blocks:  # only if left block has not been seen before\n",
    "                        new_left_blocks.append(left_block)\n",
    "                        new_right_blocks.append(right_block)\n",
    "                        seen_left_blocks.add(left_block)  # add the seen left block to the set\n",
    "    return new_left_blocks, new_right_blocks\n",
    "\n",
    "\n",
    "num_chunks = math.ceil(total_pages / pages_per_chunk)\n",
    "texts = []\n",
    "\n",
    "skip_patterns = [\n",
    "    r'JPEG|(?:__)[A-Z0-9]+-[A-Z0-9]+-[A-Z0-9]+.jpeg|[0-9]{7,}|IMG_[0-9]{4}.png|PNG Image - [0-9].[0-9] MB|PTV eX-%\\) ica\\) JPEG Image - [0-9]{2} KB',\n",
    "    'Sent as Text Message',\n",
    "    r'\\b[a-z0-9-]+(\\.[a-z0-9-]+)+\\b',\n",
    "    r'@\\)']\n",
    "\n",
    "for chunk in range(num_chunks):\n",
    "    start_page = chunk * pages_per_chunk + 1\n",
    "    end_page = min((chunk + 1) * pages_per_chunk, total_pages)\n",
    "    images = convert_pdf_to_images(pdf_path, start_page, end_page)\n",
    "\n",
    "    for image in images:\n",
    "        width, height = image.size\n",
    "        left_image = image.crop((0, 0, 0.45*width, height))\n",
    "        right_image = image.crop((0.55*width, 0, width, height))\n",
    "\n",
    "        left_text = ocr_core(left_image)\n",
    "        right_text = ocr_core(right_image)\n",
    "\n",
    "        left_blocks = split_into_blocks(left_text)\n",
    "        right_blocks = split_into_blocks(right_text)\n",
    "\n",
    "        filtered_left_blocks, filtered_right_blocks = filter_text_blocks(left_blocks, right_blocks, skip_patterns)\n",
    "        texts.extend(zip_longest(filtered_left_blocks, filtered_right_blocks, fillvalue=''))\n",
    "\n",
    "with open(output_path, 'w', newline='', encoding='utf-8') as file:\n",
    "    writer = csv.writer(file)\n",
    "    writer.writerow(['prompt', 'completion'])\n",
    "    writer.writerows(texts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fine-Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import openai\n",
    "import pandas as pd\n",
    "import string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#paste path to original excel data in Google Drive\n",
    "file_path = 'FriendMessage.csv'\n",
    "df = pd.read_csv(file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>prompt</th>\n",
       "      <th>completion</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>I don't want to\\r\\nI want to sleep but I don’t...</td>\n",
       "      <td>Not if u don’t want to</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Does that make sense</td>\n",
       "      <td>I getit</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>I have 1 hour till movie over</td>\n",
       "      <td>But it’s good to plan your sleep</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>O wait\\r\\nI meant to say u</td>\n",
       "      <td>Me too</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Not I</td>\n",
       "      <td>Oh m gee</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>373</th>\n",
       "      <td>_ I like a squeezable Mansi</td>\n",
       "      <td>I used to be a bad bitch</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>374</th>\n",
       "      <td>_ This one</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>375</th>\n",
       "      <td>It's hot 2 me</td>\n",
       "      <td>Hot Mansi better Mansi</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>376</th>\n",
       "      <td>_ Go sleepy weepy</td>\n",
       "      <td>No its not</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>377</th>\n",
       "      <td>Nou®@</td>\n",
       "      <td>Im a bad bitch Mansi from today</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>378 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                prompt  \\\n",
       "0    I don't want to\\r\\nI want to sleep but I don’t...   \n",
       "1                                 Does that make sense   \n",
       "2                        I have 1 hour till movie over   \n",
       "3                           O wait\\r\\nI meant to say u   \n",
       "4                                                Not I   \n",
       "..                                                 ...   \n",
       "373                        _ I like a squeezable Mansi   \n",
       "374                                         _ This one   \n",
       "375                                      It's hot 2 me   \n",
       "376                                  _ Go sleepy weepy   \n",
       "377                                              Nou®@   \n",
       "\n",
       "                           completion  \n",
       "0              Not if u don’t want to  \n",
       "1                             I getit  \n",
       "2    But it’s good to plan your sleep  \n",
       "3                              Me too  \n",
       "4                            Oh m gee  \n",
       "..                                ...  \n",
       "373          I used to be a bad bitch  \n",
       "374                                no  \n",
       "375            Hot Mansi better Mansi  \n",
       "376                        No its not  \n",
       "377   Im a bad bitch Mansi from today  \n",
       "\n",
       "[378 rows x 2 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "common_suffix_separator = \"\\n\\n###\\n\\n\"\n",
    "df[\"prompt\"] = df[\"prompt\"].apply(lambda x: x.strip() + common_suffix_separator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "common_suffix_ending = \"###END###\"\n",
    "df[\"completion\"] = df[\"completion\"].apply(lambda x: x.strip() + common_suffix_ending)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"completion\"] = df[\"completion\"].apply(lambda x: \" \" + x.strip())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#name your cleaned up excel file (recommend pasting the same filepath, and adding a \"p\" for pandas)\n",
    "df.to_csv('Text-Message-Data-p.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CSV file converted to JSONL format.\n"
     ]
    }
   ],
   "source": [
    "import csv\n",
    "import json\n",
    "\n",
    "# Define input and output file paths\n",
    "input_csv_file = 'Text-Message-Data-p.csv'\n",
    "output_jsonl_file = 'Text-Message-Data-p_prepared.jsonl'\n",
    "\n",
    "# Read CSV file and convert to JSONL\n",
    "with open(input_csv_file, 'r', newline='') as csvfile, open(output_jsonl_file, 'w') as jsonlfile:\n",
    "    reader = csv.DictReader(csvfile)\n",
    "    for row in reader:\n",
    "        # Convert row to JSON\n",
    "        json_data = json.dumps(row)\n",
    "        \n",
    "        # Write JSON data to JSONL file\n",
    "        jsonlfile.write(json_data + '\\n')\n",
    "\n",
    "print(\"CSV file converted to JSONL format.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## OpenAI Python client library to create a fine-tune file for training a model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import OpenAI\n",
    "\n",
    "client = OpenAI(api_key = \"put your api key here\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FileObject(id='file-HuNy1CGpsY6xavmSkMYxjwuK', bytes=38592, created_at=1710283430, filename='Text-Message-Data-p_prepared.jsonl', object='file', purpose='fine-tune', status='processed', status_details=None)\n"
     ]
    }
   ],
   "source": [
    "#Create fine-tune file and put in Google Drive\n",
    "def create_training_file(file_path):\n",
    "  file = client.files.create(\n",
    "      file=open(file_path, \"rb\"),\n",
    "      purpose=\"fine-tune\"\n",
    "  )\n",
    "  return file\n",
    "\n",
    "#copy training file path above, and paste here, ending in .jsonl\n",
    "training_file = create_training_file(\"Text-Message-Data-p_prepared.jsonl\")\n",
    "print(training_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'file-HuNy1CGpsY6xavmSkMYxjwuK'"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_file.id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "fine_tuned_model = client.fine_tuning.jobs.create(training_file=training_file.id,\n",
    "                    model ='davinci-002',\n",
    "                    hyperparameters={\n",
    "                    \"n_epochs\": 5\n",
    "                    }\n",
    "                )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FineTuningJob(id='ftjob-eZpWj6pQi12gd1QWKSOqMus7', created_at=1710284365, error=Error(code=None, message=None, param=None, error=None), fine_tuned_model=None, finished_at=None, hyperparameters=Hyperparameters(n_epochs=5, batch_size='auto', learning_rate_multiplier='auto'), model='davinci-002', object='fine_tuning.job', organization_id='org-kCgMIHV36ylNWQhRzwaOXvkd', result_files=[], status='validating_files', trained_tokens=None, training_file='file-HuNy1CGpsY6xavmSkMYxjwuK', validation_file=None, user_provided_suffix=None)\n"
     ]
    }
   ],
   "source": [
    "print(fine_tuned_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fine-tunning model with jobID: ftjob-eZpWj6pQi12gd1QWKSOqMus7.\n",
      "Training Response: FineTuningJob(id='ftjob-eZpWj6pQi12gd1QWKSOqMus7', created_at=1710284365, error=Error(code=None, message=None, param=None, error=None), fine_tuned_model=None, finished_at=None, hyperparameters=Hyperparameters(n_epochs=5, batch_size='auto', learning_rate_multiplier='auto'), model='davinci-002', object='fine_tuning.job', organization_id='org-kCgMIHV36ylNWQhRzwaOXvkd', result_files=[], status='validating_files', trained_tokens=None, training_file='file-HuNy1CGpsY6xavmSkMYxjwuK', validation_file=None, user_provided_suffix=None)\n",
      "Training Status: validating_files\n"
     ]
    }
   ],
   "source": [
    "job_id = fine_tuned_model.id\n",
    "status = fine_tuned_model.status\n",
    "\n",
    "print(f'Fine-tunning model with jobID: {job_id}.')\n",
    "print(f\"Training Response: {fine_tuned_model}\")\n",
    "print(f\"Training Status: {status}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Streaming events for the fine-tuning job: ftjob-eZpWj6pQi12gd1QWKSOqMus7\n",
      "2024-03-12 16:09:34 The job has successfully completed\n",
      "2024-03-12 16:09:31 New fine-tuned model created: ft:davinci-002:personal::925XP6lM\n",
      "2024-03-12 16:09:02 Step 1801/1890: training loss=1.79\n",
      "2024-03-12 16:08:35 Step 1701/1890: training loss=0.50\n",
      "2024-03-12 16:08:03 Step 1601/1890: training loss=1.30\n",
      "2024-03-12 16:07:35 Step 1501/1890: training loss=2.29\n",
      "2024-03-12 16:07:05 Step 1401/1890: training loss=1.29\n",
      "2024-03-12 16:06:38 Step 1301/1890: training loss=3.20\n",
      "2024-03-12 16:06:10 Step 1201/1890: training loss=3.05\n",
      "2024-03-12 16:05:43 Step 1101/1890: training loss=3.67\n",
      "2024-03-12 16:05:15 Step 1001/1890: training loss=2.82\n",
      "2024-03-12 16:04:48 Step 901/1890: training loss=0.90\n",
      "2024-03-12 16:04:18 Step 801/1890: training loss=3.09\n",
      "2024-03-12 16:03:51 Step 701/1890: training loss=5.05\n",
      "2024-03-12 16:03:23 Step 601/1890: training loss=3.39\n",
      "2024-03-12 16:02:56 Step 501/1890: training loss=1.16\n",
      "2024-03-12 16:02:28 Step 401/1890: training loss=1.76\n",
      "2024-03-12 16:01:59 Step 301/1890: training loss=2.03\n",
      "2024-03-12 16:01:31 Step 201/1890: training loss=3.29\n",
      "2024-03-12 16:01:01 Step 101/1890: training loss=5.20\n",
      "2024-03-12 16:00:29 Step 1/1890: training loss=10.43\n",
      "2024-03-12 15:59:30 Fine-tuning job started\n",
      "2024-03-12 15:59:27 Files validated, moving job to queued state\n",
      "2024-03-12 15:59:25 Validating training file: file-HuNy1CGpsY6xavmSkMYxjwuK\n",
      "2024-03-12 15:59:25 Created fine-tuning job: ftjob-eZpWj6pQi12gd1QWKSOqMus7\n"
     ]
    }
   ],
   "source": [
    "import signal\n",
    "import datetime\n",
    "\n",
    "\n",
    "def signal_handler(sig, frame):\n",
    "    status = client.fine_tuning.jobs.retrieve(job_id).status\n",
    "    print(f\"Stream interrupted. Job is still {status}.\")\n",
    "    return\n",
    "\n",
    "\n",
    "print(f\"Streaming events for the fine-tuning job: {job_id}\")\n",
    "\n",
    "signal.signal(signal.SIGINT, signal_handler)\n",
    "\n",
    "events = client.fine_tuning.jobs.list_events(fine_tuning_job_id=job_id)\n",
    "try:\n",
    "    for event in events:\n",
    "        print(\n",
    "            f'{datetime.datetime.fromtimestamp(event.created_at)} {event.message}'\n",
    "        )\n",
    "except Exception:\n",
    "    print(\"Stream interrupted (client disconnected).\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Interacting with Fine-tuned Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Example 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import OpenAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Harry: What do you want to eat?\n",
      "Mansi:  Either we can get pizza or like, what about your tacos?\" Or something like\n"
     ]
    }
   ],
   "source": [
    "new_prompt = \"What do you want to eat?\"\n",
    "answer = client.completions.create(\n",
    "  model=\"ft:davinci-002:personal::925XP6lM\",\n",
    "  prompt=new_prompt\n",
    ")\n",
    "print(\"Harry:\", new_prompt)\n",
    "print(\"Mansi:\",answer.choices[0].text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Harry: What do you want to eat?\n",
      "Mansi:  Either we can get pizza or like, what about your tacos?\n"
     ]
    }
   ],
   "source": [
    "print(\"Harry: What do you want to eat?\")\n",
    "print(\"Mansi:  Either we can get pizza or like, what about your tacos?\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Example 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 260,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Harry: What do you think about politics? And what's your views or is it just not for you?\n",
      "Mansi:  Not interested?\n",
      "\n",
      "It's something I stay away from.\n",
      "\n",
      "Why? It's very\n"
     ]
    }
   ],
   "source": [
    "new_prompt = \"What do you think about politics? And what's your views or is it just not for you?\"\n",
    "answer = client.completions.create(\n",
    "  model=\"ft:davinci-002:personal::925XP6lM\",\n",
    "  prompt=new_prompt\n",
    ")\n",
    "print(\"Harry:\", new_prompt)\n",
    "print(\"Mansi:\",answer.choices[0].text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Harry: What do you think about politics? And what's your views or is it just not for you?\n",
      "Mansi: Not interested? It's something I stay away from.\n"
     ]
    }
   ],
   "source": [
    "print(\"Harry: What do you think about politics? And what's your views or is it just not for you?\")\n",
    "print(\"Mansi: Not interested? It's something I stay away from.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Example 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 281,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Harry: Whats your favourite kind of music?\n",
      "Mansi:  Mine is alternative - https://www.youtube.com/watch?v=MOEdFPa\n"
     ]
    }
   ],
   "source": [
    "new_prompt = \"Whats your favourite kind of music?\"\n",
    "answer = client.completions.create(\n",
    "  model=\"ft:davinci-002:personal::925XP6lM\",\n",
    "  prompt=new_prompt\n",
    ")\n",
    "print(\"Harry:\", new_prompt)\n",
    "print(\"Mansi:\",answer.choices[0].text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 283,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Harry: Whats your favourite kind of music?\n",
      "Mansi: Mine is alternative.\n"
     ]
    }
   ],
   "source": [
    "print(\"Harry: Whats your favourite kind of music?\")\n",
    "print(\"Mansi: Mine is alternative.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "persona",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
